{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1484346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import feature_importances\n",
    "import featuretools as ft\n",
    "from featuretools.primitives import RollingMean, NumericLag\n",
    "import woodwork as ww\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.model_understanding import graph_prediction_vs_actual_over_time\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018874e",
   "metadata": {},
   "source": [
    "## Time Series explanation\n",
    "\n",
    "Other demos use data that is temporally ordered: predict-remaining-useful-life, predict olympic medals, predict-appointment-noshow. What all these have in common is a time index column that gives the data a temporal ordering. In those demos, the implications of that temporal ordering is that, in order to have testing and training data, we need to split the data in a way that honors that boundary before we can perform feature engineering on it. In EntitySets with multiple dataframes, this means that aggregations need to take into account cutoff times. \n",
    "\n",
    "Idea: Explain how the other temporal demos are not time series problems - they’re asking a different question \n",
    "\n",
    "In this demo, we’ll also be using data that has a temporal ordering, however, we’ll be solving a slightly different type of problem, a time series problem, and that will inform the feature engineering we perform. Featuretools and EvalML can be used to build time series machine learning models, and this demo will show how that can be done.\n",
    "\n",
    "Before we can get to building our models, we will provide further explanations of what a time series regression problem actually is.\n",
    "\n",
    "A time series regression model will make use of the inherent relationship between datapoints that are closer to one another to make predictions. There is a level of dependence between a data point and the ones that came before it. Therefore, the features used in modeling are built from the target column itself. A certain observation’s features will include information from previous observations (or rows) but cannot contain information from that observation itself. this makes including columns beyond the target and time index difficult, because the non target columns must follow those same rules. That kind of time series problem is multivariate in nature; this demo will focus on solving a univariate time series problem, or one that just uses the time index and the target column.\n",
    "\n",
    "One important aspect of time series modeling is that the data must be ordered by its time index. If the data is unordered, it’d be hard to see any overall trend or seasonality, but when sorted by date, any relationships that exist in the data can be seen and used when making predictions (winter is cold; summer is hot!). Notice how this is different from non-time series data, which can be presented in any order without having an impact on the resulting predictions.\n",
    "\n",
    "In a time series problem, our task is to predict the future values of our target variable. If we engineer the right features, we can use normal regression models; but we need to account for the temporal ordering of the data. \n",
    "\n",
    "\n",
    "## Introduce Dataset\n",
    "\n",
    "We’ll demonstrate how to build a time series model using the DailyDelhiClimateTrain dataset, which contains a meantemp target column and a date time index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529406e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_name = \"DailyDelhiClimateTrain\"\n",
    "df = pd.read_csv(f\"data/{file_name}.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a040b51c",
   "metadata": {},
   "source": [
    "Let’s take a quick look at the data to confirm that it makes sense to use this dataset for time series modeling. First, we’ll check whether there is any column with a uniform sampling frequency. This is important, because it means that there is a constant amount of time between observations, and this lets us build features more efficiently. A dataset that does not have a uniform sampling frequency can still be used for time series modeling, but the existence of that frequency is a good indicator that this dataset is ripe for time series modeling. For columns that have multiple datetime columns, checking for a frequency is also a good indicator for which should be the time index,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ww.init()\n",
    "df.ww.infer_temporal_frequencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d559a",
   "metadata": {},
   "source": [
    "Using Woodwork's `infer_temporal_frequencies` method, we see that one of the columns, `date`, has a daily frequency. This indicates to us that `date` will be our time index in the modeling process.\n",
    "\n",
    "Now, we’ll graph the data. We can see a strong seasonality, which makes sense for temperature , as, in many places, the time of the year is indicative of what the weather will look like. First, the fact that the black line, rolling std, does not have any pattern _____. The second is that the rolling mean (red line) very closely matches the actual temperature. This will be important for model building, though of course, if we make a feature out of the rolling mean, we cannot include that day's temperature in each window, or we'd be exposing the target variable.  But we also see that there's no significant trend over the course of the dataset. This is important for time series modeling. If there was a significant trend, we would need to account for it in pre-processing. Even so, we may decide to account for seasonality in prerocessing in order to _____."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c5e14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts = df['meantemp']\n",
    "ts.index = df['date']\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6942a",
   "metadata": {},
   "source": [
    "## Introduce Problem\n",
    "Now that we’ve seen that the data is a good candidate for time series modeling, let’s figure out the exact problem we’ll be solving. To do that, we’ll need to introduce a few concepts that will have an impact on our feature engineering. \n",
    "\n",
    "**forecast_horizon**: The number of time periods we are trying to forecast. In this example, we’re interested in predicting the mean temperature for the next 5 days, so the value is 5.\n",
    "\n",
    "**gap**: The number of time periods between the end of the training set and the start of the test set. We’re going to make predictions using data from three days prior to each observation.\n",
    "\n",
    "**max_delay**: The maximum number of rows to look in the past from the current row in order to compute features. Here, we’ll use a max delay of 20.\n",
    "\n",
    "**time_index**: The column of the training dataset that contains the date corresponding to each observation. Here, it's the `date` column.\n",
    "\n",
    "Our problem can then be described as trying to predict the mean temperature over the next five days using temperature data from 20 days prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only columns we'll want to use for modeling - makes this a univariate problem\n",
    "time_index = \"date\"\n",
    "target_col = 'meantemp'\n",
    "\n",
    "# parameters as evalml uses them \n",
    "gap = 3\n",
    "max_delay = 20\n",
    "forecast_horizon = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a8685",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Since we do not want to complicate the solition by performing multivariate time series modeling, we'll only use the time index column and target column for the rest of this demo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_df = df[[time_index, target_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ed90f",
   "metadata": {},
   "source": [
    "### Baseline Run\n",
    "\n",
    "Our baseline run will only include one feature that is shifted to the first known value for each observation. When splitting data, we'll need to be careful to not have the test dataset's lag feature use values that are technically before the test set begins or inside of the training set. \n",
    "\n",
    "First, let's split the data, leaving a `gap` number of observations between the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(time_target_fs):\n",
    "    # remove nans\n",
    "    max_nans = 0\n",
    "    for col in time_target_fs.columns:\n",
    "        max_nans = max( time_target_fs[col].isna().sum(), max_nans)\n",
    "    \n",
    "    if max_nans:\n",
    "        time_target_fs = time_target_fs.iloc[max_nans:]\n",
    "        \n",
    "    X = time_target_fs\n",
    "    \n",
    "    y = X.pop(target_col)\n",
    "    return X, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(univariate_df.shape[0]*0.7)\n",
    "\n",
    "# leave gap observations between training and test datasets  \n",
    "training_data = univariate_df[:split_point]\n",
    "test_data =  univariate_df[(split_point + gap):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2737ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag feature introduces nans, which we need to handle\n",
    "training_data['lag'] = training_data[target_col].shift(forecast_horizon + gap + 1)\n",
    "test_data['lag'] = test_data[target_col].shift(forecast_horizon + gap + 1)\n",
    "\n",
    "\n",
    "training_data.drop(time_index, axis=1, inplace=True)\n",
    "test_data.drop(time_index, axis=1, inplace=True)\n",
    "\n",
    "X_train, y_train = preprocess(training_data)\n",
    "X_test, y_test = preprocess(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators=100)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "preds = reg.predict(X_test)\n",
    "scores = median_absolute_error(preds, y_test)\n",
    "print('Median Abs Error: {:.2f}'.format(scores))\n",
    "\n",
    "high_imp_feats = feature_importances(X_train, reg, feats=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8d9a32",
   "metadata": {},
   "source": [
    "We can build more features, some of which may be similar to the `lag` feature we used in the baseline model, but if we look back at the graph with the rolling mean, we remember that rolling mean was a really good indicator for the mean temp. So we'll want a way of including that as a feature without exposing our target. This is where Featuretools' time series primitives comes into play. We'll also add some more standard datetime primitives that might have predictive power; for example, the month of the year is a very good indicator of what the teamperature should be.\n",
    "\n",
    "### Feature Engineering Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(univariate_df.shape[0]*0.7)\n",
    "\n",
    "# leave gap observations between training and test datasets  \n",
    "training_data = univariate_df[:split_point]\n",
    "test_data =  univariate_df[(split_point + gap):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ea229",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters as featuretools will use them\n",
    "rolling_gap = forecast_horizon + gap\n",
    "rolling_window_length = int(.25*max_delay) + 1 # a quarter is a heuristic here \n",
    "rolling_min_periods = int(.25*max_delay) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995348c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_es = ft.EntitySet()\n",
    "training_es.add_dataframe(univariate_df, \n",
    "                 dataframe_name='temperatures', \n",
    "                 index='id', \n",
    "                 make_index=True, \n",
    "                 time_index=time_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6c9e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_es = ft.EntitySet()\n",
    "test_es.add_dataframe(test_data.copy(), \n",
    "                 dataframe_name='temperatures', \n",
    "                 index='id', \n",
    "                 make_index=True, \n",
    "                 time_index=time_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496c781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datetime_featureizer = ['Day', 'Month', 'Hour', \"Year\"]\n",
    "# how is the statistically significant lags from evalml that makes up the nubmer of lags determined? \n",
    "# max delay - dets the number of features (up to - can pick any one/number )\n",
    "lagging_featureizer = [NumericLag(periods=t + forecast_horizon + gap) for t in range(forecast_horizon + gap + 1)]\n",
    "\n",
    "\n",
    "train_fm, features = ft.dfs(entityset=training_es, \n",
    "               target_dataframe_name='temperatures', \n",
    "               max_depth=1,\n",
    "               trans_primitives = datetime_featureizer + lagging_featureizer +[ \n",
    "                                   RollingMean(rolling_window_length, \n",
    "                                               gap=rolling_gap,\n",
    "                                              min_periods=rolling_min_periods)]\n",
    "              )\n",
    "\n",
    "X_train, y_train = preprocess(train_fm)\n",
    "\n",
    "train_fm.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c8b0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_fm = ft.calculate_feature_matrix(features, test_es)\n",
    "\n",
    "X_test, y_test = preprocess(test_fm)\n",
    "\n",
    "\n",
    "test_fm.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators=100)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "preds = reg.predict(X_test)\n",
    "scores = median_absolute_error(preds, y_test)\n",
    "print('Median Abs Error: {:.2f}'.format(scores))\n",
    "\n",
    "high_imp_feats = feature_importances(X_train, reg, feats=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16057c8",
   "metadata": {},
   "source": [
    "Looking at the feature importances above, we see that the rolling mean was, indeed, very predictive along with the Month feature. \n",
    "\n",
    "## Use Time Series Regression Problem From EvalML\n",
    "We will now build a model that is very similar to the one we just built with the help of Featuretools. EvalML's time series regression problem type does the same feature engineering that we just did under the hood. That, along with some other optimizations and the fact that we run multiple pipelines shows the power of EvalML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a1dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "\n",
    "univariate_df = df[[time_index, target_col]]\n",
    "\n",
    "X = univariate_df\n",
    "y = univariate_df.pop(target_col)\n",
    "\n",
    "X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y,\n",
    "                                                                   problem_type='time series regression',\n",
    "                                                                   test_size=.3,\n",
    "                                                                  problem_configuration={\"gap\": gap, \"max_delay\": max_delay,\n",
    "                                             \"forecast_horizon\": forecast_horizon, \"time_index\": time_index},)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e17b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml import AutoMLSearch\n",
    "\n",
    "# X = pd.read_csv(f\"data/{file_name}.csv\")[[time_index, target_col]]\n",
    "# X.ww.init()\n",
    "# y = X.ww.pop(target_col)\n",
    "\n",
    "\n",
    "# train_dates, test_dates = X[time_index] < \"2016-08-08\", X[time_index] >= \"2016-08-08\"\n",
    "# X_train, y_train = X.ww.loc[train_dates], y.ww.loc[train_dates]\n",
    "# X_test, y_test =  X.ww.loc[test_dates], y.ww.loc[test_dates]\n",
    "\n",
    "automl = AutoMLSearch(X_train, y_train, problem_type=\"time series regression\",\n",
    "                      max_batches=1,\n",
    "                      problem_configuration={\"gap\": gap, \"max_delay\": max_delay,\n",
    "                                             \"forecast_horizon\": forecast_horizon, \"time_index\": time_index},\n",
    "                      allowed_model_families=[\"xgboost\", \"random_forest\", \"linear_model\", \"extra_trees\",\n",
    "                                              \"decision_tree\"],\n",
    "                      objective='MedianAE'\n",
    "                      )\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2d109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "pipeline.feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb952824",
   "metadata": {},
   "source": [
    "Look at how similar the feature importances are! The top three are all the same most of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20751c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "best_pipeline_score = pipeline.score(X_test, y_test, ['R2'], X_train, y_train)['R2']\n",
    "best_pipeline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23404d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = automl.get_pipeline(0)\n",
    "baseline.fit(X_train, y_train)\n",
    "naive_baseline_score = baseline.score(X_test, y_test, ['R2'], X_train, y_train)['R2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = graph_prediction_vs_actual_over_time(pipeline, X_test, y_test, X_train, y_train, dates=X_test['date'])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = graph_prediction_vs_actual_over_time(baseline, X_test, y_test, X_train, y_train, dates=X_test['date'])\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
