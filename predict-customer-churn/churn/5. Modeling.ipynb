{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Modeling\n",
    "\n",
    "The last step in the machine learning pipeline is also where the value is derived. After we have developed the labels, each with its own cutoff time, we need to train a model to map from the features to predict the label. \n",
    "\n",
    "In this notebook, we will use the feature matrices and label times to train and test a machine learning model. We will work through a single prediction problem, predicting on the first of each month which customers will churn during the month with churn defined as no active membership for more than 31 days, a lead time of 1 month, and a prediction window of 1 month.\n",
    "\n",
    "The general process of modeling is shown below:\n",
    "\n",
    "![](../images/modeling_process.png)\n",
    "\n",
    "## Approach\n",
    "\n",
    "Our basic machine learning approach is:\n",
    "\n",
    "1. Prepare data for machine learning\n",
    "    * Fill in missing values with median imputation\n",
    "    * Encoding of categorical values\n",
    "2. Split data into training and hold out testing based on time \n",
    "3. Evaluate a baseline logistic regression model\n",
    "    * Also try a naive baseline for comparison\n",
    "4. Try a non-linear more capable classifier, the Random Forest \n",
    "    * Use mostly default hyperparameters\n",
    "    * Evaluate on hold-out testing data\n",
    "5. Inspect predictions to determine if business need has been met\n",
    "    * Precision recall curve used to tune threshold\n",
    "    * Confusion matrix to assess predictions\n",
    "    * Determine business value\n",
    "6. Optimizer model automatically using an auto-ml library\n",
    "    * Using TPOT although many options exist\n",
    "    \n",
    "The final outcome is an optimized model that solves the business problem of predicting customer churn with given parameters. The model can be deployed - used to make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:25:28.026449Z",
     "start_time": "2018-11-01T17:25:27.784837Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "PARTITION_DIR = 's3://customer-churn-spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:25:30.043651Z",
     "start_time": "2018-11-01T17:25:28.027832Z"
    }
   },
   "outputs": [],
   "source": [
    "p70_fm = pd.read_csv(f'{PARTITION_DIR}/p70/MS-31_feature_matrix.csv')\n",
    "p70_fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Data\n",
    "\n",
    "All of the data is stored in AWS S3. We'll retrieve 50 partitions of feature matrices. For this problem, we'll use a lead offset of 1 month meaning that our predictions are made one month in advance. Adjsting this value significantly affects the performance because it is harder for the model to learn meaningful relationships farther out from the end of the features (which are determined by the cutoff time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:17:50.945407Z",
     "start_time": "2018-11-02T14:17:50.941935Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_data(partition_num, label_type='MS-31'):\n",
    "    \"\"\"Retrieve features and labels and merge. Lead periods is the number of offsets\"\"\"\n",
    "\n",
    "    # Read in features and labels\n",
    "    fm = pd.read_csv(f'{PARTITION_DIR}/p{partition_num}/{label_type}_feature_matrix.csv', low_memory=False).\\\n",
    "        drop(columns=['label', 'days_to_churn', 'churn_date']).rename(\n",
    "            columns={'time': 'cutoff_time'})\n",
    "    labels = pd.read_csv(\n",
    "        f'{PARTITION_DIR}/p{partition_num}/{label_type}_labels.csv', low_memory=False)\n",
    "\n",
    "    # Merge together features and labels\n",
    "    feature_matrix = fm.merge(labels, on=[\n",
    "                              'msno', 'cutoff_time'], how='inner').sort_values(['msno', 'cutoff_time'])\n",
    "\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = retrieve_data(50)\n",
    "fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell retrieves a number of feature matrices for training and for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:18:24.842350Z",
     "start_time": "2018-11-02T14:17:56.142709Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(50)\n",
    "\n",
    "# Set number of train and testing feature matrices\n",
    "fms_to_get = 50\n",
    "\n",
    "# Choose random sample of partitions\n",
    "ps = random.sample(list(range(900)), fms_to_get)\n",
    "\n",
    "# Retrieve feature matrices from S3\n",
    "fms = []\n",
    "for i, r in enumerate(ps):\n",
    "    fm = retrieve_data(r)\n",
    "    print(f'{round(100 * (i / fms_to_get), 2)}% complete.', end='\\r')\n",
    "    if fm.shape[1] == 253:\n",
    "        fms.append(fm)\n",
    "\n",
    "# Join together and drop rows with unknown label\n",
    "feature_matrix = pd.concat(fms)\n",
    "feature_matrix = feature_matrix[~feature_matrix['label'].isna()].sort_values([\n",
    "    'msno', 'cutoff_time'])\n",
    "\n",
    "# Drop rows with no previous transactions\n",
    "feature_matrix = feature_matrix[~feature_matrix['TIME_SINCE_LAST(transactions.transaction_date)'].isna(\n",
    ")]\n",
    "\n",
    "# Remove outliers\n",
    "feature_matrix = feature_matrix[feature_matrix[\n",
    "    'TOTAL_PREVIOUS_MONTH(transactions.planned_daily_price, transaction_date)'] < 10]\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below converts the boolean types to integers for use in a machine learning model. Most of the boolean indicate whether or not all the values for customer were True (`All` primitive) or if the date was a weekend (`IsWeekend` primitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:18:45.683991Z",
     "start_time": "2018-11-02T14:18:30.256616Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix = feature_matrix.replace({'False': 0, 'True': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:18:55.294876Z",
     "start_time": "2018-11-02T14:18:51.081353Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix_original = feature_matrix.copy()\n",
    "feature_matrix.drop(columns=[c for c in ['churn', 'days_to_next_churn',\n",
    "                                         'churn_date'] if c in feature_matrix],\n",
    "                    inplace=True)\n",
    "\n",
    "bool_cols = [c for c in feature_matrix if 'ALL' in c or (\n",
    "    'WEEKEND' in c and 'PERCENT_TRUE' not in c)]\n",
    "\n",
    "for c in bool_cols:\n",
    "    feature_matrix[c] = feature_matrix[c].astype(float)\n",
    "feature_matrix[bool_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:19:06.597183Z",
     "start_time": "2018-11-02T14:19:00.643232Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix = feature_matrix.drop_duplicates(subset = ['msno', 'cutoff_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "We'll do a few basic data cleaning steps:\n",
    "\n",
    "* Remove columns with many missing values\n",
    "* Remove columns with a single unique value\n",
    "* Remove highly correlated - colinear - columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values\n",
    "\n",
    "We'll drop any columns with more than 90% missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:19:14.742053Z",
     "start_time": "2018-11-02T14:19:11.977249Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_pct = feature_matrix.isnull().sum() / len(feature_matrix)\n",
    "to_drop = list((missing_pct[missing_pct > 0.9]).index)\n",
    "to_drop = [x for x in to_drop if x != 'days_to_churn']\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:19:20.564191Z",
     "start_time": "2018-11-02T14:19:20.104884Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix.drop(columns=to_drop, inplace=True)\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Unique Value\n",
    "\n",
    "Columns with only a single unique value contain no information and hence can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:19:54.506659Z",
     "start_time": "2018-11-02T14:19:25.919536Z"
    }
   },
   "outputs": [],
   "source": [
    "one_unique = feature_matrix.apply(lambda x: x.nunique() == 1, axis=0)\n",
    "to_drop = list(one_unique[one_unique == True].index)\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:20:00.324714Z",
     "start_time": "2018-11-02T14:19:59.868925Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix.drop(columns=to_drop, inplace=True)\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highly Correlated (collinear) Columns\n",
    "\n",
    "Collinear columns can slow down training, lead to less interpretable models, and decrease generalization performance. Therefore, it's generally a good idea to remove one of each pair of highly correlated columns for machine learning. The following code identifies columns that exceed an absolute magnitude correlation of 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:21:43.532455Z",
     "start_time": "2018-11-02T14:20:05.662835Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.95\n",
    "\n",
    "# Calculate correlations\n",
    "corr_matrix = feature_matrix.corr().abs()\n",
    "\n",
    "# Subset to the upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Identify names of columns with correlation above threshold\n",
    "to_drop = [column for column in upper.columns if any(\n",
    "    upper[column] >= threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:21:48.870672Z",
     "start_time": "2018-11-02T14:21:48.868473Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f'There are {len(to_drop)} columns to drop with correlation > {threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:21:54.548857Z",
     "start_time": "2018-11-02T14:21:54.222447Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix.drop(columns=to_drop, inplace=True)\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data cleaning operations should increase the generalization performance of our model and make it more interpretable. A few simple operations can greatly improve a machine learning model and often are more effective than model optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate into Training and Testing Set\n",
    "\n",
    "We'll separate into a training and testing set based on the date. We'll use 25% of the data in the testing and 75% in the training. Separating training and testing by the date is important in time sensitive problems because it prevents data leakage and gives a better estimate of the generalization performance of the model. On real data, our model will have to make forecasts of the future, and we can try to recreate that situation by using a hold-out set from later in time than the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:00.055241Z",
     "start_time": "2018-11-02T14:21:59.923400Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix['cutoff_time'] = pd.to_datetime(feature_matrix['cutoff_time'])\n",
    "feature_matrix['cutoff_time'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below splits the data based on the time. We'll try to use about 30% of the data for testing and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:06.707453Z",
     "start_time": "2018-11-02T14:22:05.393891Z"
    }
   },
   "outputs": [],
   "source": [
    "split_date = pd.datetime(2016, 8, 1)\n",
    "\n",
    "\n",
    "train = feature_matrix.loc[feature_matrix['cutoff_time'] < split_date].copy()\n",
    "test = feature_matrix.loc[feature_matrix['cutoff_time'] >= split_date].copy()\n",
    "\n",
    "train.sort_values(['cutoff_time'], inplace=True)\n",
    "test.sort_values(['cutoff_time'], inplace=True)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train) / len(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preparation\n",
    "\n",
    "The next blocks of code get the features ready for machine learning.\n",
    "\n",
    "\n",
    "### Encoding Categoricals\n",
    "\n",
    "First we need to one hot encode the features. After doing this, we align the training and testing dataframes so they have the same columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:13.828366Z",
     "start_time": "2018-11-02T14:22:12.160961Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train.drop(columns=['cutoff_time', 'msno']))\n",
    "test = pd.get_dummies(test.drop(columns=['cutoff_time', 'msno']))\n",
    "\n",
    "train, test = train.align(test, join='inner', axis=1)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Labels\n",
    "\n",
    "Now we can extract the labels. There are two different problems: one is a binary classification of whether or not the customer will churn during the month. The other is a regression: how many days are there until the next churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:19.759075Z",
     "start_time": "2018-11-02T14:22:19.152458Z"
    }
   },
   "outputs": [],
   "source": [
    "y, test_y = np.array(train.pop('label')), np.array(test.pop('label'))\n",
    "\n",
    "y_reg, test_y_reg = np.array(train.pop('days_to_churn')), np.array(\n",
    "    test.pop('days_to_churn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:25.287809Z",
     "start_time": "2018-11-02T14:22:25.122493Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(y)\n",
    "plt.title('Label Distribution')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in Missing Values\n",
    "\n",
    "We can fill in missing values using the median of the column. As an important note, the missing test values are filled in with the median of the corresponding training feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:33.378381Z",
     "start_time": "2018-11-02T14:22:30.655544Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.replace({np.inf: np.nan, -np.inf: np.nan}).\\\n",
    "    fillna(train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:40.298649Z",
     "start_time": "2018-11-02T14:22:38.712397Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test.replace({np.inf: np.nan, -np.inf: np.nan}).\\\n",
    "    fillna(train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:48.424978Z",
     "start_time": "2018-11-02T14:22:45.671654Z"
    }
   },
   "outputs": [],
   "source": [
    "np.any(train.isnull()), np.any(np.isinf(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there are no missing values and all of the values are numeric, our data is ready for machine learning. However, before we do machine learning, we need to figure out what a naive baseline would score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Baseline\n",
    "\n",
    "For a naive baseline, we can randomly guess that a customer has churned with the same frequence of the churns in the training data. We'll assess the predictions using a number of different metrics.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "For an imbalanced classification problem, there are a number of metrics to consider:\n",
    "\n",
    "* Receiver Operating Characteristic Area Under the Curve (ROC AUC): a measure between 0 and 1 comparing the performance of the classifier when predicting probabilities across a range of thresholds.\n",
    "* Precision Score: number of true positives divided by the total number of positives predicted\n",
    "* Recall Score: number of true positives divided by the total number of actual positives in the data\n",
    "* F1 Score: Harmonic mean of precision and recall\n",
    "\n",
    "The exact metric used and the threshold that our model needs to reach depends on the business need. We can tune the model to some extent to optimize for different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:53.793360Z",
     "start_time": "2018-11-02T14:22:53.786555Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(50)\n",
    "naive_guess = np.random.binomial(1, p=np.mean(y), size=len(test_y))\n",
    "naive_guess[:10], naive_guess.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:22:59.310175Z",
     "start_time": "2018-11-02T14:22:59.189673Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (roc_auc_score, precision_score,\n",
    "                             recall_score, f1_score)\n",
    "\n",
    "print(f'Naive Baseline\\n')\n",
    "roc = roc_auc_score(test_y, np.repeat(np.mean(y), len(test_y)))\n",
    "print(f'ROC AUC: {round(roc, 4)}')\n",
    "\n",
    "for metric in [precision_score, recall_score, f1_score]:\n",
    "    print(f'{metric.__name__}: {round(metric(test_y, naive_guess), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these metrics are very poor! With no machine learning, we are only able to identify 2.9% of the customer churns and only 0.9% of the predicted churns were actually churns. A naive approach clearly does not provide much value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:23:04.666970Z",
     "start_time": "2018-11-02T14:23:04.664354Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f'The percentage of churns is {100 * round(np.mean(y), 4)}% in the training data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Now we need to see if machine learning is up to the task of improving on these predictions. We'll start simple, using a linear model to assess if this problem is easy enough to be solved with Logistic Regression. \n",
    "\n",
    "(The machine learning models are implemented in [Scikit-Learn](https://sklearn.org/)). \n",
    "\n",
    "## Baseline Model\n",
    "\n",
    "We can use a logistic regression in order to see baseline performance on this problem. If the logistic regression works well enough, then there is no need to move to a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:23:10.006207Z",
     "start_time": "2018-11-02T14:23:10.004099Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a simple function to evaluate predictions. This implements the metrics used above. (A full list of metrics in Scikit-Learn can be found in [this documentation](http://scikit-learn.org/stable/modules/classes.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:23:30.861053Z",
     "start_time": "2018-11-02T14:23:15.370337Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def evaluate(model, train, y, test, test_y):\n",
    "    \"\"\"Evaluate a machine learning model on four metrics:\n",
    "       ROC AUC, precision score, recall score, and f1 score.\n",
    "\n",
    "       Returns the model and the predictions.\"\"\"\n",
    "\n",
    "    model.fit(train, y)\n",
    "\n",
    "    # Predict probabilities and labels\n",
    "    probs = model.predict_proba(test)[:, 1]\n",
    "    preds = model.predict(test)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc = roc_auc_score(test_y, probs)\n",
    "    name = repr(model).split('(')[0]\n",
    "    print(f\"{name}\\n\")\n",
    "    print(f'ROC AUC: {round(roc, 4)}')\n",
    "\n",
    "    # Iterate through metrics\n",
    "    for metric in [precision_score, recall_score, f1_score]:\n",
    "        # Use .__name__ attribute to list metric\n",
    "        print(f'{metric.__name__}: {round(metric(test_y, preds), 4)}')\n",
    "\n",
    "    return model, preds\n",
    "\n",
    "\n",
    "model, preds = evaluate(model, train, y, test, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model does perform slightly better than guessing in terms of ROC AUC. The precision is slightly higher than the naive baseline although the recall is much lower leading to an overall reduced f1 score (with a default threshold of 0.5 for classifying positive examples). This poor performance by the logistic regression indicates the problem of separating churn from not-churn is non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complex Model\n",
    "\n",
    "For a potentially better machine learning model, we can move to the [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). From the results of the logistic regression, this looks to be a non-linear problem which means we should use a model capable of learning a non-linear decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use most of the default hyperparameters but alter a few to prevent overfitting. We can also set `class_weight = 'balanced'` to try and offset the impact of such an imbalanced classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:24:13.769241Z",
     "start_time": "2018-11-02T14:23:36.197719Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=40,\n",
    "                               min_samples_leaf=50,\n",
    "                               n_jobs=-1, class_weight='balanced',\n",
    "                               random_state=50)\n",
    "\n",
    "model, preds = evaluate(model, train, y, test, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest performance is much better than just guessing! With no tuning, the model is able to identify 36% of the customer churns and the false positives have been reduced. This should give us confidence that we can solve this problem using machine learning.\n",
    "\n",
    "# Model Validation\n",
    "\n",
    "We need to inspect the model results to determine if it meets our business needs. This includes looking at the performance as well as the feature importances. We want to make sure that our model performs well, but also try and understand _why_ it performs well. \n",
    "\n",
    "## Precision Recall Curve\n",
    "\n",
    "One of the best methods for tuning a model for a business need is through the precision recall curve. This shows the precision-recall tradeoff for different thresholds. Depending on the business requirement, we can change the threshold for classifying a positive example to alter the balance of true positives, false positives, false negatives, and true negatives. There will always be a tradeoff between precision and recall, but we can try to find the right balance by visually and quantitatively assessing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:25:35.035697Z",
     "start_time": "2018-11-02T14:25:33.835263Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "def plot_precision_recall(test_y, probs, title='Precision Recall Curve', threshold_selected=None):\n",
    "    \"\"\"Plot a precision recall curve for predictions. \n",
    "       Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py\"\"\"\n",
    "\n",
    "    precision, recall, threshold = precision_recall_curve(test_y, probs)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall', size=18)\n",
    "    plt.ylabel('Precision', size=18)\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(title, size=20)\n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "\n",
    "    if threshold_selected:\n",
    "        p = precision(np.where(threshold == threshold_selected)[0])\n",
    "        r = recall(np.where(threshold == threshold_selected)[0])\n",
    "        plt.scatter(r, p, marker='*', size=200)\n",
    "        plt.vlines(r, ymin=0, ymax=p, linestyles='--')\n",
    "        plt.hlines(p, xmin=0, xmax=r, linestyles='--')\n",
    "\n",
    "    pr = pd.DataFrame({'precision': precision[:-1], 'recall': recall[:-1],\n",
    "                       'threshold': threshold})\n",
    "    return pr\n",
    "\n",
    "\n",
    "probs = model.predict_proba(test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    test_y, probs, title='Precision-Recall Curve for Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query the dataframe to find the threshold required for a given precision or recall. For example, to find the threshold for a precision of 25%, we use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:25:40.482343Z",
     "start_time": "2018-11-02T14:25:40.473079Z"
    }
   },
   "outputs": [],
   "source": [
    "precision_above = pr_data.loc[pr_data['precision'] >= 0.25].copy()\n",
    "precision_above.sort_values('recall', ascending=False, inplace=True)\n",
    "precision_above.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that if we want a precision of 25%, then our recall will be 42.5%. This means we'll miss over 50% of the true churns in the data.\n",
    "\n",
    "### Adjusting for the Business Requirement\n",
    "\n",
    "Let's say we are required to have a recall of 75% in our model. This means our model finds 75% of the true churns in the data. We'll work through the rest of this notebook under this assumption. To find the threshold, we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:25:45.919210Z",
     "start_time": "2018-11-02T14:25:45.903261Z"
    }
   },
   "outputs": [],
   "source": [
    "recall_attained = 0.75\n",
    "recall_above = pr_data.loc[pr_data['recall'] >= recall_attained].copy()\n",
    "recall_above.sort_values('precision', ascending=False, inplace=True)\n",
    "recall_above.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:25:51.366613Z",
     "start_time": "2018-11-02T14:25:51.361519Z"
    }
   },
   "outputs": [],
   "source": [
    "precision_attained = recall_above.iloc[0, 0]\n",
    "threshold_required = recall_above.iloc[0, -1]\n",
    "\n",
    "print(\n",
    "    f'At a threshold of {round(threshold_required, 4)} the recall is {100 * recall_attained:.2f}% and the precision is {round(100 * precision_attained, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that in order to identify 75% of the actual churns, we'll have to accept that only 8.31% of the predicted positives are actually positive churns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:25:56.835965Z",
     "start_time": "2018-11-02T14:25:56.830238Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(test_y, probs, title='Precision Recall Curve', threshold_selected=None):\n",
    "    \"\"\"Plot a precision recall curve for predictions. \n",
    "       Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py\"\"\"\n",
    "\n",
    "    precision, recall, threshold = precision_recall_curve(test_y, probs)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall', size=24)\n",
    "    plt.ylabel('Precision', size=24)\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(title, size=24)\n",
    "    plt.xticks(size=18)\n",
    "    plt.yticks(size=18)\n",
    "\n",
    "    if threshold_selected:\n",
    "        p = precision[np.where(threshold == threshold_selected)[0]]\n",
    "        r = recall[np.where(threshold == threshold_selected)[0]]\n",
    "        plt.scatter(r, p, marker='*', s=600, c='r')\n",
    "        plt.vlines(r, ymin=0, ymax=p, linestyles='--')\n",
    "        plt.hlines(p, xmin=0, xmax=r, linestyles='--')\n",
    "        plt.text(r - 0.1, p + 0.15,\n",
    "                 s=f'Threshold: {round(threshold_selected, 2)}', size=20, fontdict={'weight': 1000})\n",
    "        plt.text(r - 0.2, p + 0.075,\n",
    "                 s=f'Precision: {round(100 * p[0], 2)}% Recall: {round(100 * r[0], 2)}%', size=20,\n",
    "                 fontdict={'weight': 1000})\n",
    "\n",
    "    pr = pd.DataFrame({'precision': precision[:-1], 'recall': recall[:-1],\n",
    "                       'threshold': threshold})\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:26:02.834919Z",
     "start_time": "2018-11-02T14:26:02.234828Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_data = plot_precision_recall(test_y, probs, title='Precision-Recall Curve for Tuned Random Forest',\n",
    "                                threshold_selected=threshold_required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A confusion matrix is often a useful way to visualize predictions. This shows the true values along the top row and the predicted values along the bottom row. Looking at the different cells, we can see where the model performed well and where it did not do so well.\n",
    "\n",
    "We'll use the threshold identified above to construct the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:26:11.562493Z",
     "start_time": "2018-11-02T14:26:11.556827Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.YlOrRd):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.style.use('bmh')\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, size=22)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size=20)\n",
    "    plt.yticks(tick_marks, classes, size=20)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 size=20)\n",
    "    plt.grid(None)\n",
    "    plt.ylabel('True label', size=22)\n",
    "    plt.xlabel('Predicted label', size=22)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:26:17.628613Z",
     "start_time": "2018-11-02T14:26:17.257426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions where probability is above threshold\n",
    "preds = np.zeros(len(test_y))\n",
    "preds[probs >= threshold_required] = 1\n",
    "\n",
    "# Make and plot confusion matrix\n",
    "cm = confusion_matrix(test_y, preds)\n",
    "plot_confusion_matrix(cm, classes=['No Churn', 'Churn'],\n",
    "                      title='Churn Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we satisfy our business requirement, this is the best prediction of what our performance would be on new data. The model is able to identiy 75% of churned customers compared to a baseline of around 3%. The precision has increased from the baseline 1% to 8%, a relative increase of over 800%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances\n",
    "\n",
    "As one method for trying to understand how the model makes decisions, we can look at the most important features. The absolute value of the importances is not as useful as is the relative ranking of the features which is determined by how well the feature separates the classes when building the decision trees in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:26:23.177390Z",
     "start_time": "2018-11-02T14:26:23.067796Z"
    }
   },
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'importance': model.feature_importances_}, index=train.columns).\\\n",
    "    sort_values('importance', ascending=False)\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:26:29.038265Z",
     "start_time": "2018-11-02T14:26:28.626806Z"
    }
   },
   "outputs": [],
   "source": [
    "fi.iloc[:10]['importance'].plot.barh(color='r', edgecolor='k',\n",
    "                                     figsize=(14, 10), linewidth=2)\n",
    "ax = plt.gca()\n",
    "ax.invert_yaxis()\n",
    "plt.xticks(size=20)\n",
    "plt.yticks(size=18)\n",
    "plt.title('Most Important Features', size=28);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see why these features are important, we can plot the distribution colored by the value of the label.\n",
    "We'll look at both a kernel density estimate plot and an empirical cumulative distribution frequency diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:26:37.798636Z",
     "start_time": "2018-11-02T14:26:37.795673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspiration: https://campus.datacamp.com/courses/statistical-thinking-in-python-part-1/graphical-exploratory-data-analysis?ex=12\n",
    "def ecdf(x):\n",
    "    n = len(x)\n",
    "    x = np.sort(x)\n",
    "    y = np.arange(1, n + 1) / n\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:26:47.088922Z",
     "start_time": "2018-11-02T14:26:43.721046Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "train_with_labels = train.copy()\n",
    "train_with_labels['label'] = y\n",
    "train_with_labels = train_with_labels.loc[train_with_labels[\n",
    "    'TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)'] < 200]\n",
    "\n",
    "train_with_labels['TIME_SINCE_LAST(transactions.transaction_date)'] = train_with_labels[\n",
    "    'TIME_SINCE_LAST(transactions.transaction_date)'] / (3600 * 24)\n",
    "train_with_labels['AVG_TIME_BETWEEN(transactions.transaction_date)'] = train_with_labels[\n",
    "    'AVG_TIME_BETWEEN(transactions.transaction_date)'] / (3600 * 24)\n",
    "\n",
    "# Iterate through features\n",
    "for feature in ['TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)',\n",
    "                'TIME_SINCE_LAST(transactions.transaction_date)',\n",
    "                'AVG_TIME_BETWEEN(transactions.transaction_date)',\n",
    "                'SUM(transactions.payment_plan_days WHERE is_auto_renew = 1)',\n",
    "                'LAST(transactions.payment_method_id)']:\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    # Iterate through values of the label\n",
    "    for label, grouped in train_with_labels.groupby('label'):\n",
    "        # Plot the distribution of the feature\n",
    "        sns.kdeplot(grouped[feature].dropna(),\n",
    "                    label='Churned' if label == 1 else 'No Churn')\n",
    "    # Plot labeling\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlabel(f'{feature.capitalize()}')\n",
    "    plt.title(f'Distribution of {feature.capitalize()}', size=28)\n",
    "    plt.legend(prop={'size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through features\n",
    "for feature, name in zip(['TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)',\n",
    "                'TIME_SINCE_LAST(transactions.transaction_date)'], \n",
    "                         ['Total Spending in Month before Cutoff Time', \n",
    "                           'Time Since Last Transaction']):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    # Iterate through values of the label\n",
    "    for label, grouped in train_with_labels.groupby('label'):\n",
    "        # Plot the distribution of the feature\n",
    "        sns.kdeplot(grouped[feature].dropna(),\n",
    "                    label='Churned' if label == 1 else 'No Churn')\n",
    "    # Plot labeling\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlabel(f'{name}')\n",
    "    plt.title(f'Distribution of {name}', size=28)\n",
    "    plt.legend(prop={'size': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are significant differences between those customers who churned and those who did not. Most noticeably, the customers who churned had less activity in the previous month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T14:26:59.228469Z",
     "start_time": "2018-11-02T14:26:52.838590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through features\n",
    "for feature, name in zip(['TOTAL_PREVIOUS_MONTH(transactions.actual_amount_paid, transaction_date)',\n",
    "                          'TIME_SINCE_LAST(transactions.transaction_date)',\n",
    "                          'AVG_TIME_BETWEEN(transactions.transaction_date)'],\n",
    "                         ['Total Spent in Previous Month',\n",
    "                          'Time Since Last Transaction',\n",
    "                          'Average Time Between Transactions']):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Iterate through values of the label\n",
    "    for label, grouped in train_with_labels.groupby('label'):\n",
    "        xs, ys = ecdf(grouped[feature])\n",
    "\n",
    "        # Plot the distribution of the feature\n",
    "        plt.plot(xs, ys, marker='.', ms=10,\n",
    "                 label='Churned' if label == 1 else 'No Churn')\n",
    "\n",
    "    # Plot labeling\n",
    "    plt.ylabel('Percentile')\n",
    "    plt.xlabel(f'{name.capitalize()}')\n",
    "    plt.title(f'ECDF of {name.capitalize()}', size=28)\n",
    "    plt.legend(prop={'size': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "\n",
    "Now we will use the trained model to make predictions on the hold-out testing set. We'll can make predictions in terms of probabilities and then threshold them to labels using our selected threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:30:08.834747Z",
     "start_time": "2018-11-01T17:30:07.762294Z"
    }
   },
   "outputs": [],
   "source": [
    "new_probs = model.predict_proba(test)[:, 1]\n",
    "\n",
    "\n",
    "oos_ids = list(feature_matrix.loc[feature_matrix['cutoff_time'] >= split_date, 'msno'])\n",
    "oos_cutoff_time = list(feature_matrix.loc[feature_matrix['cutoff_time'] >= split_date, 'cutoff_time'])\n",
    "\n",
    "prediction_df = pd.DataFrame({'msno': oos_ids, 'cutoff_time': oos_cutoff_time,\n",
    "                              'probability': new_probs})\n",
    "prediction_df['prediction'] = prediction_df['probability'] > threshold_required\n",
    "prediction_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:30:09.074346Z",
     "start_time": "2018-11-01T17:30:08.856576Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_df['probability'].plot.hist(bins=20, edgecolor='k')\n",
    "plt.axvline(x=threshold_required, color='r', linewidth=2)\n",
    "plt.title('Distribution of Predicted Probabilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fairly confident that most of the predictions are not churns. Moreover, there are a number of probabilities that are exactly the same as can be seen in the [empirical cumulative density function](https://en.wikipedia.org/wiki/Empirical_distribution_function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:30:09.616714Z",
     "start_time": "2018-11-01T17:30:09.075790Z"
    }
   },
   "outputs": [],
   "source": [
    "xs, ys = ecdf(prediction_df['probability'])\n",
    "plt.plot(xs, ys, marker='.')\n",
    "plt.title('ECDF of Predicted Probobabilities')\n",
    "plt.axvline(x=threshold_required, color='r', linewidth=2)\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Percentile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Value Analysis\n",
    "\n",
    "Using the metrics from the model, we can conduct an analysis of the business value of our solution. We'll use the precision and recall along with a few assumptions.\n",
    "\n",
    "* Typical plan price = 150 (NTD)\n",
    "* Reduced plan price = 130 (NTD)\n",
    "* Recall = 75%\n",
    "* Precision = 8.31%\n",
    "* Conversion Rate = 75%\n",
    "\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "We can scale our analysis to the entire dataset since we only used a subset of it for modeling. We'll assume we are able to achieve the same performance on the entire dataset, which is reasonable because the accuracy of a model generally improves as the amount of data used increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_price = 150\n",
    "r_plan_price = 130\n",
    "recall = recall_attained\n",
    "precision = precision_attained\n",
    "conversion_rate = 0.75\n",
    "\n",
    "# Find total number of members\n",
    "n_members = pd.read_csv('../data/members_v3.csv', usecols = ['msno']).shape[0]\n",
    "monthly_revenue = n_members * plan_price\n",
    "churn_rate = np.mean(feature_matrix['label'])\n",
    "\n",
    "churns = int(churn_rate * n_members)\n",
    "# Find the typical monthly revenue lost to churned customers\n",
    "revenue_lost_churns = n_members * churn_rate * plan_price\n",
    "print(f'Typical monthly revenue lost to {churns} churned customers = ${revenue_lost_churns:,.2f} (NTD).')\n",
    "print(f'Typical total monthly revenue = ${monthly_revenue:,.2f}.')\n",
    "print(f'Churns losses represent {100 * (revenue_lost_churns / monthly_revenue):.2f}% of monthly revenue.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find stats for entire dataset\n",
    "true_positives = int(churns * recall)\n",
    "false_negatives = int(churns - true_positives)\n",
    "false_positives = int((true_positives * (1 - precision)) / precision)\n",
    "\n",
    "print(f'True positives: {true_positives}; False negatives: {false_negatives}; False positives: {false_positives}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we'll make sure the precision and recall metrics come out right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(true_positives) / (true_positives + false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(true_positives) / (true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things look right here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_lost_false_positives = false_positives * (plan_price - r_plan_price)\n",
    "revenue_lost_false_negatives = false_negatives * plan_price\n",
    "revenue_recouped_true_positives = conversion_rate * (true_positives * r_plan_price)\n",
    "\n",
    "print(f'Cost from false positives = ${revenue_lost_false_positives:,.2f} (NTD); Cost from false negatives = ${revenue_lost_false_negatives:,.2f} (NTD)')\n",
    "print(f'Revenue recouped from true positives = ${revenue_recouped_true_positives:,.2f} (NTD).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_effect = revenue_lost_churns - (-revenue_recouped_true_positives + revenue_lost_false_positives + revenue_lost_false_negatives)\n",
    "us_dollars = total_effect * 0.033\n",
    "print(f'Total Effect of identifying churns ${total_effect:,.2f} (NTD) = ${us_dollars:,.2f} (USD).')\n",
    "print(f'This represents {100 * (total_effect / revenue_lost_churns):.2f}% of the losses due to churns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has successfully solved the business problem, recouping over 10% of the losses due to churns. This does require a number of assumptions, but with additional refinement, our model could probably deliver even greater value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Model Optimization Using TPOT\n",
    "\n",
    "If we are not pleased with the model results using an off-the-shelf algorithm from Scikit-Learn, there are a number of libraries for searching for the best model without any manual intervention. One of the easiest-to-se libraries is known as TPOT. This will search through hundreds of machine learning models, using evolutionary algorithms to guide the discovery process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the models, we'll use a TimeSeriesSplit. This makes three splits of the data based on the indexes so we need to ensure that our data is sorted by time (already done). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:30:09.620226Z",
     "start_time": "2018-11-01T17:30:09.618193Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a `TPOTClassifier` object and pass in a few parameters. This particular use case will search 100 models, using `f1` scoring, the TimeSeriesSplit for cross validation, and taking advantage of all the cores on our machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:30:09.794067Z",
     "start_time": "2018-11-01T17:30:09.621639Z"
    }
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Make tpot pipeline\n",
    "tpot_pipeline = TPOTClassifier(generations=10, population_size=10,\n",
    "                               cv=tss, scoring='f1',\n",
    "                               n_jobs=-1, verbosity=2,\n",
    "                               random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.693Z"
    }
   },
   "outputs": [],
   "source": [
    "tpot_pipeline.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.700Z"
    }
   },
   "outputs": [],
   "source": [
    "tpot_pipeline.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.706Z"
    }
   },
   "outputs": [],
   "source": [
    "tpot_pipeline.export('best_pipeline_new.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Pipeline\n",
    "\n",
    "The following code shows the best pipeline exported by TPOT. We can just copy the code, train a model, and make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.714Z"
    }
   },
   "outputs": [],
   "source": [
    "from pygments import highlight\n",
    "from pygments.lexers import PythonLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "import IPython\n",
    "\n",
    "with open('best_pipeline.py') as f:\n",
    "    code = f.read()\n",
    "\n",
    "formatter = HtmlFormatter()\n",
    "IPython.display.HTML('<style type=\"text/css\">{}</style>{}'.format(\n",
    "    formatter.get_style_defs('.highlight'),\n",
    "    highlight(code, PythonLexer(), formatter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.720Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "exported_pipeline = ExtraTreesClassifier(bootstrap=False,\n",
    "                                         criterion=\"entropy\",\n",
    "                                         max_features=0.1,\n",
    "                                         min_samples_leaf=5,\n",
    "                                         min_samples_split=8,\n",
    "                                         n_estimators=100,\n",
    "                                         random_state=50,\n",
    "                                         n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.724Z"
    }
   },
   "outputs": [],
   "source": [
    "model, preds = evaluate(exported_pipeline, train, y, test, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the same procedure as before, looking at the precision recall curve and finding the threshold needed for a recall of 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.730Z"
    }
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    test_y, probs, title='Precision-Recall Curve for Optimized Pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.735Z"
    }
   },
   "outputs": [],
   "source": [
    "recall_above = pr_data.loc[pr_data['recall'] >= recall_attained].copy()\n",
    "recall_above.sort_values('precision', ascending=False, inplace=True)\n",
    "recall_above.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.739Z"
    }
   },
   "outputs": [],
   "source": [
    "precision_attained = recall_above.iloc[0, 0]\n",
    "threshold_required = recall_above.iloc[0, -1]\n",
    "\n",
    "print(\n",
    "    f'At a threshold of {round(threshold_required, 4)} the recall is {100 * recall_attained:.2f}% and the precision is {round(100 * precision_attained, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Classifier built by hand does basically the sameas the TPOT optimized model. Running the optimization for longer may result in a better model. However, in terms of time investment, a better option is probably to spend more time on feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-01T17:25:28.743Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = np.zeros(len(test_y))\n",
    "preds[probs >= threshold_required] = 1\n",
    "\n",
    "cm = confusion_matrix(test_y, preds)\n",
    "plot_confusion_matrix(cm, classes=['No Churn', 'Churn'],\n",
    "                      title='Optimized Model Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Our final tuned model was able to achieve a recall of 75% and a precision of 8.31%, a significant increase over the naive baseline of 3.5% recall and 1.0% precision. \n",
    "\n",
    "Overall, the final metrics from modeling are:\n",
    "\n",
    "| Model                                     | ROC AUC | Recall | Precision | F1 Score |\n",
    "|-------------------------------------------|---------|--------|-----------|----------|\n",
    "| Naive Baseline (no ml)                    | 0.5     | 3.47%  | 1.04%     | 0.016   |\n",
    "| Logistic Regression                       | 0.577   | 0.51%  | 2.91%     | 0.009   |\n",
    "| Random Forest Default                     | 0.929   | 65.2%  | 14.7%     | 0.240   |\n",
    "| Random Forest Tuned for 75% Recall        | 0.929   | 75%    | 8.31%     | 0.150    |\n",
    "| Auto-optimized Model                      | 0.927   | 2.88%  | 64.4%     | 0.055   |\n",
    "| Auto-optimized Model Tuned for 75% Recall | 0.927   | 75%    | 9.58%     | 0.170    |\n",
    "\n",
    "With these metrics, we can conclude that machine learning has solved the business problem of identifying customers that will churn in the next month. We can now use this model to predict customers at risk for churning in the future. An analysis of the business payback also showed that the final model delivered significant value. The predictions would then be handed off to the customer engagement team to hopefully reduce the number of churns.\n",
    "\n",
    "The framework for solving this problem - and for solving any problem with machine learning - was:\n",
    "\n",
    "1. Prediction Engineering: define the business objective, translate into a machine learning task, and create a set of labeled historical examples with cutoff time from the data.\n",
    "2. Feature Engineering: use the label times to automatically build hundreds of relevant and valid features for each label.\n",
    "3. Modeling: use a machine learning algorithm implemented in common Python libraries to train a model to predit the labels from the features. Validate and tune model for the business need and then make predictions on new data.\n",
    "\n",
    "![](../images/Framework.png)\n",
    "\n",
    "This approach solves a number of problems: it standardizes the traditionally ad-hoc process of solving a problem with machine learning and it is general so that nearly the same code can be used for multiple prediction problems on the same dataset. The benefits of machine learning have been limited to a few companies both because of the lack of a shared language for expressing and solving problems, and because each solution requires custom code and must be completely rebuilt for a different prediction problem. By codifying the processes needed to solve problems with machine learning, we aim to make it easier for companies to use this transformational technology. \n",
    "\n",
    "Furthermore, the framework lets data scientists fill in the details with existing tools allowing for rapid development and deployment of model pipelines. The achievements of machine learning are already impressive, but with a scaffolding in place the benefits can be extended to a broader population.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
