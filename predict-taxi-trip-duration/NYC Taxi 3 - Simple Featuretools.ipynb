{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.featuretools.com/\"><img src=\"img/featuretools-logo.png\" width=\"400\" height=\"200\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> A Featuretools Baseline </h2>\n",
    "<p>The following tutorial illustrates a featuretools baseline model for the NYC Taxi Trip Duration competition on Kaggle. This notebook follows the structure of the previous worksheet, but uses deep feature synthesis to create the model.</p>\n",
    "\n",
    "<h2>Step 1: Download raw data </h2>\n",
    "<p>As always, if you have not yet downloaded the data it can be found at the <a href=\"https://www.kaggle.com/c/nyc-taxi-trip-duration/data\">Kaggle website</a>. After installing featuretools following <a href = \"https://docs.featuretools.com/\">the instructions in the documentation</a> you can run the following.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import featuretools as ft\n",
    "import taxi_utils\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "ft.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>False</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>False</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>False</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>False</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>False</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id     pickup_datetime  passenger_count  \\\n",
       "0  id2875421          2 2016-03-14 17:24:55                1   \n",
       "1  id2377394          1 2016-06-12 00:43:35                1   \n",
       "2  id3858529          2 2016-01-19 11:35:24                1   \n",
       "3  id3504673          2 2016-04-06 19:32:31                1   \n",
       "4  id2181028          2 2016-03-26 13:30:55                1   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.982155        40.767937         -73.964630         40.765602   \n",
       "1        -73.980415        40.738564         -73.999481         40.731152   \n",
       "2        -73.979027        40.763939         -74.005333         40.710087   \n",
       "3        -74.010040        40.719971         -74.012268         40.706718   \n",
       "4        -73.973053        40.793209         -73.972923         40.782520   \n",
       "\n",
       "   store_and_fwd_flag  trip_duration  \n",
       "0               False            455  \n",
       "1               False            663  \n",
       "2               False           2124  \n",
       "3               False            429  \n",
       "4               False            435  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIR = \"data/train.csv\"\n",
    "TEST_DIR = \"data/test.csv\"\n",
    "\n",
    "data_train, data_test = taxi_utils.read_data(TRAIN_DIR, TEST_DIR)\n",
    "\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2: Prepare the Data </h2>\n",
    "<p>Let's create another column to define test and train datasets.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['test_data'] = False\n",
    "data_test['test_data'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can now combine the data. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_train, data_test], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3: Create baseline features using DFS </h2>\n",
    "<p>Instead of manually creating features, such as month of <b>pickup_datetime</b>, we can let featuretools come up with them. </p>\n",
    "\n",
    "<p>Within featuretools there is a standard format for representing data that is used to set up predictions and build features. A <b>EntitySet</b> stores information about dataframes (database table), columns in the dataframes, relationships, and the data itself. </p>\n",
    "\n",
    "<p> First, we create the EntitySet.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(\"taxi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the `add_dataframe` method to add a dataframe called <i>trips</i>. We want to track the `id`, the `time_index` and specify other column types we care about in this table.\n",
    "\n",
    "<p>As a note: Featuretools will try to interpret the types of columns. We can override this interpretation by specifying the types. In this case, I wanted <b>passenger_count</b> to be a type of Ordinal, and <b>vendor_id</b> to be of type Categorical.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: taxi\n",
       "  DataFrames:\n",
       "    trips [Rows: 2050266, Columns: 11]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from woodwork.logical_types import Ordinal\n",
    "trip_logical_types = {\n",
    "    'passenger_count': Ordinal(order=list(range(0, 10))), \n",
    "    'vendor_id': 'Categorical',\n",
    "}\n",
    "\n",
    "es.add_dataframe(dataframe_name=\"trips\",\n",
    "                 dataframe=data,\n",
    "                 index=\"id\",\n",
    "                 time_index='pickup_datetime',\n",
    "                 logical_types=trip_logical_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>test_data</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>vendor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id0190469</th>\n",
       "      <td>40.829182</td>\n",
       "      <td>-73.938828</td>\n",
       "      <td>id0190469</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01 00:00:17</td>\n",
       "      <td>40.719158</td>\n",
       "      <td>-73.981743</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>849.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id0621643</th>\n",
       "      <td>40.769379</td>\n",
       "      <td>-73.969330</td>\n",
       "      <td>id0621643</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:22</td>\n",
       "      <td>40.716881</td>\n",
       "      <td>-73.981850</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id1384355</th>\n",
       "      <td>40.891788</td>\n",
       "      <td>-73.854263</td>\n",
       "      <td>id1384355</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:28</td>\n",
       "      <td>40.733562</td>\n",
       "      <td>-73.976501</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id1665586</th>\n",
       "      <td>40.717491</td>\n",
       "      <td>-73.958038</td>\n",
       "      <td>id1665586</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:53</td>\n",
       "      <td>40.747166</td>\n",
       "      <td>-73.985085</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id1210365</th>\n",
       "      <td>40.815170</td>\n",
       "      <td>-73.947479</td>\n",
       "      <td>id1210365</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01 00:01:01</td>\n",
       "      <td>40.801041</td>\n",
       "      <td>-73.965279</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>408.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3719493</th>\n",
       "      <td>40.675968</td>\n",
       "      <td>-73.973160</td>\n",
       "      <td>id3719493</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:39</td>\n",
       "      <td>40.791576</td>\n",
       "      <td>-73.978416</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2609.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2150126</th>\n",
       "      <td>40.730469</td>\n",
       "      <td>-73.986427</td>\n",
       "      <td>id2150126</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:41</td>\n",
       "      <td>40.771900</td>\n",
       "      <td>-73.956070</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id1217141</th>\n",
       "      <td>40.729523</td>\n",
       "      <td>-73.986160</td>\n",
       "      <td>id1217141</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:47</td>\n",
       "      <td>40.737583</td>\n",
       "      <td>-73.997437</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3505355</th>\n",
       "      <td>40.655403</td>\n",
       "      <td>-73.959808</td>\n",
       "      <td>id3505355</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:53</td>\n",
       "      <td>40.679993</td>\n",
       "      <td>-73.964203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3004672</th>\n",
       "      <td>40.756680</td>\n",
       "      <td>-73.990173</td>\n",
       "      <td>id3004672</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30 23:59:58</td>\n",
       "      <td>40.732029</td>\n",
       "      <td>-73.988129</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050266 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dropoff_latitude  dropoff_longitude         id passenger_count  \\\n",
       "id0190469         40.829182         -73.938828  id0190469               5   \n",
       "id0621643         40.769379         -73.969330  id0621643               2   \n",
       "id1384355         40.891788         -73.854263  id1384355               1   \n",
       "id1665586         40.717491         -73.958038  id1665586               1   \n",
       "id1210365         40.815170         -73.947479  id1210365               5   \n",
       "...                     ...                ...        ...             ...   \n",
       "id3719493         40.675968         -73.973160  id3719493               1   \n",
       "id2150126         40.730469         -73.986427  id2150126               1   \n",
       "id1217141         40.729523         -73.986160  id1217141               1   \n",
       "id3505355         40.655403         -73.959808  id3505355               1   \n",
       "id3004672         40.756680         -73.990173  id3004672               1   \n",
       "\n",
       "              pickup_datetime  pickup_latitude  pickup_longitude  \\\n",
       "id0190469 2016-01-01 00:00:17        40.719158        -73.981743   \n",
       "id0621643 2016-01-01 00:00:22        40.716881        -73.981850   \n",
       "id1384355 2016-01-01 00:00:28        40.733562        -73.976501   \n",
       "id1665586 2016-01-01 00:00:53        40.747166        -73.985085   \n",
       "id1210365 2016-01-01 00:01:01        40.801041        -73.965279   \n",
       "...                       ...              ...               ...   \n",
       "id3719493 2016-06-30 23:59:39        40.791576        -73.978416   \n",
       "id2150126 2016-06-30 23:59:41        40.771900        -73.956070   \n",
       "id1217141 2016-06-30 23:59:47        40.737583        -73.997437   \n",
       "id3505355 2016-06-30 23:59:53        40.679993        -73.964203   \n",
       "id3004672 2016-06-30 23:59:58        40.732029        -73.988129   \n",
       "\n",
       "           store_and_fwd_flag  test_data  trip_duration vendor_id  \n",
       "id0190469               False      False          849.0         2  \n",
       "id0621643               False       True            NaN         2  \n",
       "id1384355               False       True            NaN         1  \n",
       "id1665586               False      False         1294.0         1  \n",
       "id1210365               False      False          408.0         2  \n",
       "...                       ...        ...            ...       ...  \n",
       "id3719493               False      False         2609.0         2  \n",
       "id2150126               False       True            NaN         2  \n",
       "id1217141               False       True            NaN         1  \n",
       "id3505355               False       True            NaN         1  \n",
       "id3004672               False       True            NaN         1  \n",
       "\n",
       "[2050266 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es['trips']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can also normalize some of the columns to create new dataframes. So a <i>vendors</i> dataframe is created based on the unique values in the <i>vendor_id</i> column in <i>trips</i>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: taxi\n",
       "  DataFrames:\n",
       "    trips [Rows: 2050266, Columns: 11]\n",
       "    vendors [Rows: 2, Columns: 2]\n",
       "    passenger_cnt [Rows: 8, Columns: 2]\n",
       "  Relationships:\n",
       "    trips.vendor_id -> vendors.vendor_id\n",
       "    trips.passenger_count -> passenger_cnt.passenger_count"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.normalize_dataframe(base_dataframe_name=\"trips\",\n",
    "                       new_dataframe_name=\"vendors\",\n",
    "                       index=\"vendor_id\")\n",
    "\n",
    "es.normalize_dataframe(base_dataframe_name=\"trips\",\n",
    "                       new_dataframe_name=\"passenger_cnt\",\n",
    "                       index=\"passenger_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can specify the time for each instance of the target dataframe to calculate features. The timestamp represents the last time data can be used for calculating features by DFS. This is specified using a dataframe of cutoff times. Below we can see that the cutoff time for each trip is the pickup time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_time = es['trips'][['id', 'pickup_datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.add_interesting_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize EntitySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Title: taxi Pages: 1 -->\n",
       "<svg width=\"486pt\" height=\"303pt\"\n",
       " viewBox=\"0.00 0.00 486.00 303.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 299)\">\n",
       "<title>taxi</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-299 482,-299 482,4 -4,4\"/>\n",
       "<!-- trips -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>trips</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"120,-98.5 120,-294.5 358,-294.5 358,-98.5 120,-98.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"239\" y=\"-279.3\" font-family=\"Times,serif\" font-size=\"14.00\">trips (2050266 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"120,-271.5 358,-271.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-256.3\" font-family=\"Times,serif\" font-size=\"14.00\">dropoff_latitude : Double</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-241.3\" font-family=\"Times,serif\" font-size=\"14.00\">dropoff_longitude : Double</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-226.3\" font-family=\"Times,serif\" font-size=\"14.00\">id : Unknown; index</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-211.3\" font-family=\"Times,serif\" font-size=\"14.00\">passenger_count : Ordinal; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-196.3\" font-family=\"Times,serif\" font-size=\"14.00\">pickup_datetime : Datetime; time_index</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-181.3\" font-family=\"Times,serif\" font-size=\"14.00\">pickup_latitude : Double</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\">pickup_longitude : Double</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-151.3\" font-family=\"Times,serif\" font-size=\"14.00\">store_and_fwd_flag : Boolean</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-136.3\" font-family=\"Times,serif\" font-size=\"14.00\">test_data : Boolean</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-121.3\" font-family=\"Times,serif\" font-size=\"14.00\">trip_duration : Double</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-106.3\" font-family=\"Times,serif\" font-size=\"14.00\">vendor_id : Categorical; foreign_key</text>\n",
       "</g>\n",
       "<!-- vendors -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>vendors</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-61.5 230,-61.5 230,-0.5 0,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"115\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\">vendors (2 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-38.5 230,-38.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\">vendor_id : Categorical; index</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">first_trips_time : Datetime; time_index</text>\n",
       "</g>\n",
       "<!-- trips&#45;&gt;vendors -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>trips&#45;&gt;vendors</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M175,-98.32C175,-98.32 175,-71.69 175,-71.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.5,-71.69 175,-61.69 171.5,-71.69 178.5,-71.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-73.8\" font-family=\"Times,serif\" font-size=\"14.00\">vendor_id</text>\n",
       "</g>\n",
       "<!-- passenger_cnt -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>passenger_cnt</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"248,-0.5 248,-61.5 478,-61.5 478,-0.5 248,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\">passenger_cnt (8 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"248,-38.5 478,-38.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"256\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\">passenger_count : Ordinal; index</text>\n",
       "<text text-anchor=\"start\" x=\"256\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">first_trips_time : Datetime; time_index</text>\n",
       "</g>\n",
       "<!-- trips&#45;&gt;passenger_cnt -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>trips&#45;&gt;passenger_cnt</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M303,-98.32C303,-98.32 303,-71.69 303,-71.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.5,-71.69 303,-61.69 299.5,-71.69 306.5,-71.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"257.5\" y=\"-73.8\" font-family=\"Times,serif\" font-size=\"14.00\">passenger_count</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f9b05275d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Given this dataset, we would have about 2 million unique cutoff times. This is a good use case to use the approximate features parameter of DFS. In a large dataset, direct features that are aggregations on the prediction dataframe may not change much from cutoff time to cutoff time. Calculating the aggregation features at specific times every hour and using it for all cutoff times within the hour would save time and perhaps not lose much information. The approximate parameter in DFS lets you specify a window size to use when approximating these direct aggregation features.</p>\n",
    "\n",
    "<p>We now create features using DFS.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 96 features\n",
      "Elapsed: 02:08 | Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "trans_primitives = ['Minute', 'Hour', 'Day', 'Week', 'Month', 'Weekday', 'Is_weekend']\n",
    "\n",
    "feature_matrix, features = ft.dfs(entityset=es,\n",
    "                                  target_dataframe_name=\"trips\",\n",
    "                                  trans_primitives=trans_primitives,\n",
    "                                  drop_contains=['trips.test_data'],\n",
    "                                  verbose=True,\n",
    "                                  cutoff_time=cutoff_time,\n",
    "                                  approximate='36d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here are the features created. Notice how some of the features match the manually created features in the previous notebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: dropoff_latitude>,\n",
       " <Feature: dropoff_longitude>,\n",
       " <Feature: passenger_count>,\n",
       " <Feature: pickup_latitude>,\n",
       " <Feature: pickup_longitude>,\n",
       " <Feature: store_and_fwd_flag>,\n",
       " <Feature: test_data>,\n",
       " <Feature: trip_duration>,\n",
       " <Feature: vendor_id>,\n",
       " <Feature: DAY(pickup_datetime)>,\n",
       " <Feature: HOUR(pickup_datetime)>,\n",
       " <Feature: IS_WEEKEND(pickup_datetime)>,\n",
       " <Feature: MINUTE(pickup_datetime)>,\n",
       " <Feature: MONTH(pickup_datetime)>,\n",
       " <Feature: WEEK(pickup_datetime)>,\n",
       " <Feature: WEEKDAY(pickup_datetime)>,\n",
       " <Feature: vendors.COUNT(trips)>,\n",
       " <Feature: vendors.MAX(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MAX(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.MAX(trips.pickup_latitude)>,\n",
       " <Feature: vendors.MAX(trips.pickup_longitude)>,\n",
       " <Feature: vendors.MAX(trips.trip_duration)>,\n",
       " <Feature: vendors.MEAN(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MEAN(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.MEAN(trips.pickup_latitude)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3: Build the Model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We need to retrieve our labels for the train dataset, so we should merge our current feature matrix with the original dataset. </p>\n",
    "<p>We also get the log of the trip duration so that a more linear relationship can be found.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert integer columns with pd.NA values to doubles to prevent XGB error\n",
    "for col in feature_matrix.columns:\n",
    "    if feature_matrix[col].dtype == 'Int64':\n",
    "        feature_matrix[col] = feature_matrix[col].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separates the whole feature matrix into train data feature matrix, train data labels, and test data feature matrix \n",
    "X_train, labels, X_test = taxi_utils.get_train_test_fm(feature_matrix)\n",
    "labels = np.log(labels.values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.00486\tvalid-rmse:5.00461\n",
      "[10]\ttrain-rmse:1.01991\tvalid-rmse:1.02032\n",
      "[20]\ttrain-rmse:0.61401\tvalid-rmse:0.61639\n",
      "[30]\ttrain-rmse:0.52868\tvalid-rmse:0.53225\n",
      "[40]\ttrain-rmse:0.49999\tvalid-rmse:0.50487\n",
      "[50]\ttrain-rmse:0.48259\tvalid-rmse:0.48853\n",
      "[59]\ttrain-rmse:0.46825\tvalid-rmse:0.47509\n",
      "Modeling RMSE 0.47509\n"
     ]
    }
   ],
   "source": [
    "model = taxi_utils.train_xgb(X_train, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build the model automatically\n",
    "<p align=\"center\">\n",
    "<img width=50% src=\"https://evalml-web-images.s3.amazonaws.com/evalml_horizontal.svg\" alt=\"Featuretools\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Up to now, we have been training a single xgboost model. However, there are many different model types that could be useful. Common ones include Catboost, LightGBM, and Random Forest Models. Using [EvalML](https://evalml.alteryx.com/en/stable/), an open source autoML library created by Alteryx, we can automatically build and tune multiple models, as well as compare the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import AutoMLSearch\n",
    "\n",
    "automl = AutoMLSearch(X_train=X_train,\n",
    "                      y_train=labels,\n",
    "                      problem_type=\"regression\",\n",
    "                      objective=\"root mean squared error\")\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline = RegressionPipeline(component_graph={'Imputer': ['Imputer', 'X', 'y'], 'One Hot Encoder': ['One Hot Encoder', 'Imputer.x', 'y'], 'XGBoost Regressor': ['XGBoost Regressor', 'One Hot Encoder.x', 'y']}, parameters={'Imputer':{'categorical_impute_strategy': 'most_frequent', 'numeric_impute_strategy': 'mean', 'categorical_fill_value': None, 'numeric_fill_value': None}, 'One Hot Encoder':{'top_n': 10, 'features_to_encode': None, 'categories': None, 'drop': 'if_binary', 'handle_unknown': 'ignore', 'handle_missing': 'error'}, 'XGBoost Regressor':{'eta': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'n_jobs': -1}}, random_seed=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "pipeline.fit(X_train, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with evalML, we were able to create a model with a better RMSE than just building a simple xgboost model. In the last part of the demo, where we incorporate custom features, we will exclusively use evalML for model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 4: Make a Submission </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id0621643    7.145653\n",
       "id1384355    7.597363\n",
       "id2568735    7.089373\n",
       "id3700764    6.964109\n",
       "id3008929    5.869703\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pipeline.predict(X_test)\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('trip_duration_ft_simple.csv', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Additional Analysis</h2>\n",
    "<p>Let's look at how important each feature was for the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pickup_longitude</td>\n",
       "      <td>2808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dropoff_latitude</td>\n",
       "      <td>2643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pickup_latitude</td>\n",
       "      <td>1968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dropoff_longitude</td>\n",
       "      <td>1812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DAY(pickup_datetime)</td>\n",
       "      <td>702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>vendors.SUM(trips.dropoff_longitude)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>vendors.MODE(trips.passenger_count)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vendors.MIN(trips.trip_duration)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vendors.MAX(trips.trip_duration)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>passenger_cnt.WEEKDAY(first_trips_time)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature_name  importance\n",
       "4                          pickup_longitude      2808.0\n",
       "0                          dropoff_latitude      2643.0\n",
       "3                           pickup_latitude      1968.0\n",
       "1                         dropoff_longitude      1812.0\n",
       "7                      DAY(pickup_datetime)       702.0\n",
       "..                                      ...         ...\n",
       "43     vendors.SUM(trips.dropoff_longitude)         0.0\n",
       "30      vendors.MODE(trips.passenger_count)         0.0\n",
       "29         vendors.MIN(trips.trip_duration)         0.0\n",
       "19         vendors.MAX(trips.trip_duration)         0.0\n",
       "93  passenger_cnt.WEEKDAY(first_trips_time)         0.0\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X_train.columns.values\n",
    "ft_importances = taxi_utils.feature_importances(model, feature_names)\n",
    "ft_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img width=50% src=\"https://alteryx-open-source-images.s3.amazonaws.com/OpenSource_Logo-01.jpg\" alt=\"ayx_os\" />\n",
    "</p>\n",
    "\n",
    "Featuretools was created by the developers at [Alteryx](https://www.alteryx.com). If building impactful data science pipelines is important to you or your business, please [get in touch](https://www.alteryx.com/contact-us/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
